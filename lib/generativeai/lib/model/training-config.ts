/**
 * Generative AI Service Management API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings. 

Use the Generative AI service management API to create and manage [dedicated AI clusters](#/en/generative-ai/latest/DedicatedAiCluster/), [endpoints](#/en/generative-ai/latest/Endpoint/), [custom models](#/en/generative-ai/latest/Model/), and [work requests](#/en/generative-ai/latest/WorkRequest/) in the Generative AI service. For example, create a custom model by fine-tuning an out-of-the-box model using your own data, on a fine-tuning dedicated AI cluster. Then, create a hosting dedicated AI cluster with an endpoint to host your custom model. 

To access your custom model endpoints, or to try the out-of-the-box models to generate text, summarize, and create text embeddings see the [Generative AI Inference API](/iaas/api/#/en/generative-ai-inference/latest/).

To learn more about the service, see the [Generative AI documentation](/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 * 
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2024, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import * as model from "../model";
import common = require("oci-common");

/**
 * The fine-tuning method and hyperparameters used for fine-tuning a custom model.
 */
export interface TrainingConfig {
  /**
   * The maximum number of training epochs to run for. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
   */
  "totalTrainingEpochs"?: number;
  /**
   * The initial learning rate to be used during training Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
   */
  "learningRate"?: number;
  /**
   * The batch size used during training. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
   */
  "trainingBatchSize"?: number;
  /**
   * Stop training if the loss metric does not improve beyond 'early_stopping_threshold' for this many times of evaluation.
   *  Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
   */
  "earlyStoppingPatience"?: number;
  /**
   * How much the loss must improve to prevent early stopping. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
   */
  "earlyStoppingThreshold"?: number;
  /**
    * Determines how frequently to log model metrics. 
* <p>
Every step is logged for the first 20 steps and then follows this parameter for log frequency. Set to 0 to disable logging the model metrics.
*  Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
    */
  "logModelMetricsIntervalInSteps"?: number;

  "trainingConfigType": string;
}

export namespace TrainingConfig {
  export function getJsonObj(obj: TrainingConfig): object {
    const jsonObj = { ...obj, ...{} };

    if (obj && "trainingConfigType" in obj && obj.trainingConfigType) {
      switch (obj.trainingConfigType) {
        case "LORA_TRAINING_CONFIG":
          return model.LoraTrainingConfig.getJsonObj(
            <model.LoraTrainingConfig>(<object>jsonObj),
            true
          );
        case "VANILLA_TRAINING_CONFIG":
          return model.VanillaTrainingConfig.getJsonObj(
            <model.VanillaTrainingConfig>(<object>jsonObj),
            true
          );
        case "TFEW_TRAINING_CONFIG":
          return model.TFewTrainingConfig.getJsonObj(
            <model.TFewTrainingConfig>(<object>jsonObj),
            true
          );
        default:
          if (common.LOG.logger)
            common.LOG.logger.info(`Unknown value for: ${obj.trainingConfigType}`);
      }
    }
    return jsonObj;
  }
  export function getDeserializedJsonObj(obj: TrainingConfig): object {
    const jsonObj = { ...obj, ...{} };

    if (obj && "trainingConfigType" in obj && obj.trainingConfigType) {
      switch (obj.trainingConfigType) {
        case "LORA_TRAINING_CONFIG":
          return model.LoraTrainingConfig.getDeserializedJsonObj(
            <model.LoraTrainingConfig>(<object>jsonObj),
            true
          );
        case "VANILLA_TRAINING_CONFIG":
          return model.VanillaTrainingConfig.getDeserializedJsonObj(
            <model.VanillaTrainingConfig>(<object>jsonObj),
            true
          );
        case "TFEW_TRAINING_CONFIG":
          return model.TFewTrainingConfig.getDeserializedJsonObj(
            <model.TFewTrainingConfig>(<object>jsonObj),
            true
          );
        default:
          if (common.LOG.logger)
            common.LOG.logger.info(`Unknown value for: ${obj.trainingConfigType}`);
      }
    }
    return jsonObj;
  }
}
