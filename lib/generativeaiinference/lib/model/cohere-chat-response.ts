/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings. 

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to [chat](#/EN/generative-ai-inference/latest/ChatResult/Chat), [generate text](#/EN/generative-ai-inference/latest/GenerateTextResult/GenerateText), [summarize](#/EN/generative-ai-inference/latest/SummarizeTextResult/SummarizeText), and [create text embeddings](#/EN/generative-ai-inference/latest/EmbedTextResult/EmbedText).

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the [Generative AI service management API](#/EN/generative-ai/latest/) to [create a custom model](#/EN/generative-ai/latest/Model/) by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a [fine-tuning dedicated AI cluster](#/EN/generative-ai/latest/DedicatedAiCluster/). Then, create a [hosting dedicated AI cluster](#/EN/generative-ai/latest/DedicatedAiCluster/) with an [endpoint](#/en/generative-ai/latest/Endpoint/) to host your custom model. For resource management in the Generative AI service, use the [Generative AI service management API](#/EN/generative-ai/latest/).

To learn more about the service, see the [Generative AI documentation](/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 * 
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import * as model from "../model";
import common = require("oci-common");

/**
 * The response to the chat conversation.
 */
export interface CohereChatResponse extends model.BaseChatResponse {
  /**
   * Contents of the response that the model generates.
   */
  "text": string;
  /**
   * The list of previous messages between the user and the model. The chat history gives the model context for responding to the user's inputs.
   */
  "chatHistory"?: Array<model.CohereMessage>;
  /**
   * Inline citations for the generated response.
   */
  "citations"?: Array<model.Citation>;
  /**
   * If set to true, a search for documents is required.
   */
  "isSearchRequired"?: boolean;
  /**
   * Why the generation stopped.
   */
  "finishReason": CohereChatResponse.FinishReason;
  /**
   * If there is an error during the streaming scenario, then the {@code errorMessage} parameter contains details for the error.
   */
  "errorMessage"?: string;
  /**
   * The generated search queries.
   */
  "searchQueries"?: Array<model.SearchQuery>;
  /**
    * The documents that the model can refer to when generating a response. Each document is a JSON string that represents the field and values of the document.
* <p>
Example:
* '[
*   {
*     \"id\": \"doc_0\",
*     \"snippet\": \"Emperor penguins are the tallest.\",
*     \"title\": \"Tall penguins\"
*   },
*   {
*     \"id\": \"doc_1\",
*     \"snippet\": \"Emperor penguins only live in Antarctica.\",
*     \"title\": \"Penguin habitats\"
*   }
* ]'
* 
    */
  "documents"?: Array<any>;
  /**
   * A list of tool calls generated by the model.
   */
  "toolCalls"?: Array<model.CohereToolCall>;
  /**
   * The full prompt that was sent to the model if isEcho is true when request.
   */
  "prompt"?: string;

  "apiFormat": string;
}

export namespace CohereChatResponse {
  export enum FinishReason {
    Complete = "COMPLETE",
    ErrorToxic = "ERROR_TOXIC",
    ErrorLimit = "ERROR_LIMIT",
    Error = "ERROR",
    UserCancel = "USER_CANCEL",
    MaxTokens = "MAX_TOKENS",
    /**
     * This value is used if a service returns a value for this enum that is not recognized by this
     * version of the SDK.
     */
    UnknownValue = "UNKNOWN_VALUE"
  }

  export function getJsonObj(obj: CohereChatResponse, isParentJsonObj?: boolean): object {
    const jsonObj = {
      ...(isParentJsonObj ? obj : (model.BaseChatResponse.getJsonObj(obj) as CohereChatResponse)),
      ...{
        "chatHistory": obj.chatHistory
          ? obj.chatHistory.map(item => {
              return model.CohereMessage.getJsonObj(item);
            })
          : undefined,
        "citations": obj.citations
          ? obj.citations.map(item => {
              return model.Citation.getJsonObj(item);
            })
          : undefined,

        "searchQueries": obj.searchQueries
          ? obj.searchQueries.map(item => {
              return model.SearchQuery.getJsonObj(item);
            })
          : undefined,

        "toolCalls": obj.toolCalls
          ? obj.toolCalls.map(item => {
              return model.CohereToolCall.getJsonObj(item);
            })
          : undefined
      }
    };

    return jsonObj;
  }
  export const apiFormat = "COHERE";
  export function getDeserializedJsonObj(
    obj: CohereChatResponse,
    isParentJsonObj?: boolean
  ): object {
    const jsonObj = {
      ...(isParentJsonObj
        ? obj
        : (model.BaseChatResponse.getDeserializedJsonObj(obj) as CohereChatResponse)),
      ...{
        "chatHistory": obj.chatHistory
          ? obj.chatHistory.map(item => {
              return model.CohereMessage.getDeserializedJsonObj(item);
            })
          : undefined,
        "citations": obj.citations
          ? obj.citations.map(item => {
              return model.Citation.getDeserializedJsonObj(item);
            })
          : undefined,

        "searchQueries": obj.searchQueries
          ? obj.searchQueries.map(item => {
              return model.SearchQuery.getDeserializedJsonObj(item);
            })
          : undefined,

        "toolCalls": obj.toolCalls
          ? obj.toolCalls.map(item => {
              return model.CohereToolCall.getDeserializedJsonObj(item);
            })
          : undefined
      }
    };

    return jsonObj;
  }
}
