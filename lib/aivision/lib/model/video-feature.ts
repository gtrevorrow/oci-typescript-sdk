/**
 * Vision API
 * Using Vision, you can upload images to detect and classify objects in them. If you have lots of images, you can process them in batch using asynchronous API endpoints. Vision's features are thematically split between Document AI for document-centric images, and Image Analysis for object and scene-based images. Pretrained models and custom models are supported.
 * OpenAPI spec version: 20220125
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2024, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import * as model from "../model";
import common = require("oci-common");

/**
 * Details about a video feature request.
 */
export interface VideoFeature {
  "featureType": string;
}

export namespace VideoFeature {
  export function getJsonObj(obj: VideoFeature): object {
    const jsonObj = { ...obj, ...{} };

    if (obj && "featureType" in obj && obj.featureType) {
      switch (obj.featureType) {
        case "OBJECT_DETECTION":
          return model.VideoObjectDetectionFeature.getJsonObj(
            <model.VideoObjectDetectionFeature>(<object>jsonObj),
            true
          );
        case "FACE_DETECTION":
          return model.VideoFaceDetectionFeature.getJsonObj(
            <model.VideoFaceDetectionFeature>(<object>jsonObj),
            true
          );
        case "TEXT_DETECTION":
          return model.VideoTextDetectionFeature.getJsonObj(
            <model.VideoTextDetectionFeature>(<object>jsonObj),
            true
          );
        case "OBJECT_TRACKING":
          return model.VideoObjectTrackingFeature.getJsonObj(
            <model.VideoObjectTrackingFeature>(<object>jsonObj),
            true
          );
        case "LABEL_DETECTION":
          return model.VideoLabelDetectionFeature.getJsonObj(
            <model.VideoLabelDetectionFeature>(<object>jsonObj),
            true
          );
        default:
          if (common.LOG.logger) common.LOG.logger.info(`Unknown value for: ${obj.featureType}`);
      }
    }
    return jsonObj;
  }
  export function getDeserializedJsonObj(obj: VideoFeature): object {
    const jsonObj = { ...obj, ...{} };

    if (obj && "featureType" in obj && obj.featureType) {
      switch (obj.featureType) {
        case "OBJECT_DETECTION":
          return model.VideoObjectDetectionFeature.getDeserializedJsonObj(
            <model.VideoObjectDetectionFeature>(<object>jsonObj),
            true
          );
        case "FACE_DETECTION":
          return model.VideoFaceDetectionFeature.getDeserializedJsonObj(
            <model.VideoFaceDetectionFeature>(<object>jsonObj),
            true
          );
        case "TEXT_DETECTION":
          return model.VideoTextDetectionFeature.getDeserializedJsonObj(
            <model.VideoTextDetectionFeature>(<object>jsonObj),
            true
          );
        case "OBJECT_TRACKING":
          return model.VideoObjectTrackingFeature.getDeserializedJsonObj(
            <model.VideoObjectTrackingFeature>(<object>jsonObj),
            true
          );
        case "LABEL_DETECTION":
          return model.VideoLabelDetectionFeature.getDeserializedJsonObj(
            <model.VideoLabelDetectionFeature>(<object>jsonObj),
            true
          );
        default:
          if (common.LOG.logger) common.LOG.logger.info(`Unknown value for: ${obj.featureType}`);
      }
    }
    return jsonObj;
  }
}
